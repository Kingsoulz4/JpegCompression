{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c94c7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding channel y\n",
      "Encoding channel Cb\n",
      "Encoding channel Cr\n",
      "huff v shape  (210, 140)\n",
      "data huff v shape  (210, 140)\n",
      "Saved\n",
      "huff u shape  (210, 140)\n",
      "data huff v shape  (210, 140)\n",
      "huff u shape  (420, 280)\n",
      " Huff y flatten string shape:  ()\n",
      "data huff v shape  (420, 280)\n",
      "Decoding channel y\n",
      "420 280\n",
      "Decoding channel Cb\n",
      "210 140\n",
      "Decoding channel Cr\n",
      "210 140\n",
      "22.665807723999023\n",
      "72.6139132976532\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import ExporterFileText\n",
    "\n",
    "from Decode import jpeg_decode, ycbcr_to_rgb\n",
    "from Encode import rgb_to_ycbcr, subsampling_422, jpeg_encode\n",
    "\n",
    "start = time.time()\n",
    "# Read image\n",
    "img_path = 'old_street.jpg'\n",
    "img = cv2.imread(img_path)\n",
    "#img1 = cv2.resize(img, (400, 400), interpolation=cv2.INTER_LINEAR)\n",
    "img1 = img\n",
    "# Convert the image to YCbCr color spaces\n",
    "width, height, _ = img1.shape\n",
    "ycbcr_image = cv2.cvtColor(img1, cv2.COLOR_BGR2YCR_CB)\n",
    "ycbcr_image = ycbcr_image\n",
    "y, u, v = cv2.split(ycbcr_image)\n",
    "# Subsample Cb and Cr components using 4:2:2 sampling\n",
    "subsampled_y, subsampled_u, subsampled_v = subsampling_422(ycbcr_image)\n",
    "# Encoding each channel\n",
    "print(\"Encoding channel y\")\n",
    "huff_y, huff_table_y = jpeg_encode(subsampled_y, quality=50)\n",
    "end1 = time.time()\n",
    "print(\"Encoding channel Cb\")\n",
    "huff_u, huff_table_u = jpeg_encode(subsampled_u, quality=50)\n",
    "end2 = time.time()\n",
    "print(\"Encoding channel Cr\")\n",
    "huff_v, huff_table_v = jpeg_encode(subsampled_v, quality=50)\n",
    "\n",
    "\n",
    "# v channel\n",
    "print(\"huff v shape \", np.array(huff_v).shape)\n",
    "\n",
    "np.savez_compressed('data_huff_v.npz', huff_v)\n",
    "\n",
    "dict_data = np.load('data_huff_v.npz')\n",
    "# extract the first array\n",
    "data_huff_v = dict_data['arr_0']\n",
    "\n",
    "print(\"data huff v shape \", np.array(data_huff_v).shape)\n",
    "\n",
    "# u channel\n",
    "\n",
    "np.save('data_huff_u_txt.txt', np.array(huff_u))\n",
    "print(\"Saved\")\n",
    "\n",
    "print(\"huff u shape \", np.array(huff_u).shape)\n",
    "\n",
    "np.savez_compressed('data_huff_u.npz', huff_u)\n",
    "\n",
    "dict_data = np.load('data_huff_u.npz')\n",
    "# extract the first array\n",
    "data_huff_u = dict_data['arr_0']\n",
    "\n",
    "print(\"data huff v shape \", np.array(data_huff_u).shape)\n",
    "\n",
    "# y channel\n",
    "\n",
    "print(\"huff u shape \", np.array(huff_y).shape)\n",
    "huff_y_string = map(str, huff_y)\n",
    "huff_y_flatten = np.array(huff_y)\n",
    "huff_y_flatten.flatten()\n",
    "huff_y_flatten_string = map(str, huff_y_flatten)\n",
    "np.savez_compressed('data_huff_y.npz', huff_y)\n",
    "np.savez_compressed('data_huff_y_string.npz', huff_y_string)\n",
    "print(\" Huff y flatten string shape: \", np.array( huff_y_flatten_string).shape)\n",
    "np.savez_compressed('data_huff_y_flatten_string.npz', huff_y_flatten_string)\n",
    "\n",
    "dict_data = np.load('data_huff_y.npz')\n",
    "# extract the first array\n",
    "data_huff_y = dict_data['arr_0']\n",
    "\n",
    "print(\"data huff v shape \", np.array(data_huff_y).shape)\n",
    "\n",
    "\n",
    "\n",
    "# huff_y_key = 'huff_y'\n",
    "# huff_u_key = 'huff_u'\n",
    "# huff_v_key = 'huff_v'\n",
    "# huff_table_y_key = 'huff_table_y'\n",
    "# huff_table_u_key = 'huff_table_u'\n",
    "# huff_table_v_key = 'huff_table_v'\n",
    "\n",
    "# np.savez_compressed('data_huff.npz', huff_y_key = huff_y, huff_u_key = huff_u, huff_v_key = huff_v, \n",
    "#                     huff_table_y_key = huff_table_y, huff_table_u_key = huff_table_u, huff_table_v_key = huff_table_v)\n",
    "\n",
    "# dict_data = np.load('data_huff.npz')\n",
    "# # extract the first array\n",
    "# data_huff_v = dict_data[huff_v_key]\n",
    "\n",
    "# print(\"huff v shape \", np.array(huff_v).shape)\n",
    "# print(\"data huff v shape \", np.array(data_huff_v).shape)\n",
    "\n",
    "huff_y_key = 'huff_y'\n",
    "huff_u_key = 'huff_u'\n",
    "huff_v_key = 'huff_v'\n",
    "huff_table_y_key = 'huff_table_y'\n",
    "huff_table_u_key = 'huff_table_u'\n",
    "huff_table_v_key = 'huff_table_v'\n",
    "\n",
    "data_args = {}\n",
    "data_args[huff_y_key] = huff_y\n",
    "data_args[huff_u_key] = huff_u\n",
    "data_args[huff_v_key] = huff_v\n",
    "data_args[huff_table_y_key] = huff_table_y\n",
    "data_args[huff_table_u_key] = huff_table_u\n",
    "data_args[huff_table_v_key] = huff_table_v\n",
    "\n",
    "ExporterFileText.ExportToText(data_args)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "end3 = time.time()\n",
    "# Decoding\n",
    "print(\"Decoding channel y\")\n",
    "y_decoded = jpeg_decode(huff_y, huff_table_y, 50)\n",
    "end4 = time.time()\n",
    "print(\"Decoding channel Cb\")\n",
    "u_decoded = jpeg_decode(huff_u, huff_table_u, 50)\n",
    "end5 = time.time()\n",
    "print(\"Decoding channel Cr\")\n",
    "v_decoded = jpeg_decode(huff_v, huff_table_v, 50)\n",
    "end6 = time.time()\n",
    "# Show result\n",
    "h, w = y_decoded.shape\n",
    "u_decoded = cv2.resize(u_decoded, (w, h), interpolation=cv2.INTER_LINEAR)\n",
    "v_decoded = cv2.resize(v_decoded, (w, h), interpolation=cv2.INTER_LINEAR)\n",
    "img_decoded = cv2.merge([y_decoded, u_decoded, v_decoded])\n",
    "img_decoded = img_decoded\n",
    "img_decoded = img_decoded.astype(np.uint8)\n",
    "# Convert image to RGB\n",
    "img_decoded_rgb = cv2.cvtColor(img_decoded, cv2.COLOR_YCrCb2BGR) #ycbcr_to_rgb(img_decoded)\n",
    "print(end1 - start)\n",
    "print(end4 - start)\n",
    "cv2.imshow('input', img1)\n",
    "cv2.imshow('JPEG img', img_decoded_rgb)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6222e95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved\n"
     ]
    }
   ],
   "source": [
    "# u channel\n",
    "\n",
    "np.savez('data_huff_u_txt.npz', huff_u)\n",
    "print(\"Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2adae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(huff_v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1708e443",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
